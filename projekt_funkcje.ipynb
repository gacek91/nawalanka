{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ładujemy pakiety potrzebne do odpalenia funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import stats\n",
    "import mne\n",
    "import pandas\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja ładowania plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_epo_fif(directory, show_output=False):\n",
    "    os.chdir(directory)\n",
    "    files = glob.glob(\"*epo.fif\")\n",
    "    if show_output:\n",
    "        print(files)\n",
    "        return files\n",
    "    else:\n",
    "        return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja tworzenia listy epok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_epoch_list(directory, files, show_output=False):\n",
    "    epoch_list = []\n",
    "    for this_file in files:\n",
    "        full_path = os.path.join(directory, this_file)\n",
    "        epochs = mne.read_epochs(full_path, verbose=False)\n",
    "        epoch_list.append(epochs)\n",
    "    if show_output:\n",
    "        print(epoch_list)\n",
    "        return epoch_list\n",
    "    else:\n",
    "        return epoch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja tworzenia listy erpów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_erp_list(epoch_list, show_output=False):\n",
    "    erp_list = list()\n",
    "    for epochs in epoch_list:\n",
    "        erp_list.append(epochs.average())\n",
    "    if show_output:\n",
    "        print(erp_list)\n",
    "        return erp_list\n",
    "    else:\n",
    "        return erp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja tworzenia słowników dla lats i peaks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lats_then_peaks(pika_var, epoch_list, conditions):\n",
    "    peaks = dict()\n",
    "    lats  = dict()\n",
    "    lp_dict = {'lats': lats, 'peaks':peaks}\n",
    "    for cond in conditions:\n",
    "        peaks[cond] = list()\n",
    "        lats[cond] = list()\n",
    "        for each in epoch_list:\n",
    "            val, lat = pika_var.transform(each[cond].average())\n",
    "            peaks[cond].append(val)\n",
    "            lats[cond].append(lat)\n",
    "    return lats, peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja - Test Levene'a [niepotrzebny ale zostawiłem dla potomnych]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levene_lats_then_peaks(lats, peaks):\n",
    "    lats_list = []\n",
    "    for k in lats.keys():\n",
    "        lats_list.append(lats[k])\n",
    "    peaks_list = []\n",
    "    for kk in peaks.keys():\n",
    "        peaks_list.append(peaks[kk])\n",
    "\n",
    "    levene_lats = stats.levene(lats_list[0],lats_list[1],lats_list[2],lats_list[3],lats_list[4],lats_list[5])\n",
    "    levene_peaks = stats.levene(peaks_list[0],peaks_list[1],peaks_list[2],peaks_list[3],peaks_list[4],peaks_list[5])\n",
    "    levene_list = ['lats','peaks']\n",
    "    levene_p_list = [round(levene_lats[1],2),round(levene_peaks[1],2)]\n",
    "    if levene_lats[1] > 0.05:\n",
    "        levene_lats_v = 'equal'\n",
    "    else:\n",
    "        levene_lats_v = 'not equal'\n",
    "    if levene_peaks[1] > 0.05:\n",
    "        levene_peaks_v = 'equal'\n",
    "    else:\n",
    "        levene_peaks_v = 'not equal'\n",
    "    levene_v_list = [levene_lats_v, levene_peaks_v]\n",
    "    df_levene_dict = {'cond':levene_list, 'p':levene_p_list, 'verdict':levene_v_list}\n",
    "    col_levene_list = ['cond', 'p','verdict']\n",
    "    print(\"Levene test for equal variances\")\n",
    "    return pandas.DataFrame(data=df_levene_dict, columns = col_levene_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja - test normalności rozkładu dla lats i peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shapiro_lats_then_peaks(lats, peaks):\n",
    "\n",
    "    cond_list = []\n",
    "    shap_p_list_lats = []\n",
    "    shap_ver_list_lats = []\n",
    "\n",
    "    for each in lats:\n",
    "        shap_result = stats.shapiro(lats[each])\n",
    "        cond_list.append(each)\n",
    "        shap_p_list_lats.append(round(shap_result[1],2))\n",
    "    ind_shap_p = [[],[]]\n",
    "    for index, each_shap_p in enumerate(shap_p_list_lats):\n",
    "        ind_shap_p[0].append(index)\n",
    "        ind_shap_p[1].append(each_shap_p)\n",
    "        if ind_shap_p[1][index] > 0.05:\n",
    "            shap_ver_list_lats.append(\"normal\")\n",
    "        else:\n",
    "            shap_ver_list_lats.append(\"not normal\")\n",
    "            \n",
    "    cond_list = []\n",
    "    shap_p_list_peaks = []\n",
    "    shap_ver_list_peaks = []\n",
    "\n",
    "    for each in peaks:\n",
    "        shap_result = stats.shapiro(peaks[each])\n",
    "        cond_list.append(each)\n",
    "        shap_p_list_peaks.append(round(shap_result[1],2))\n",
    "    ind_shap_p = [[],[]]\n",
    "    for index, each_shap_p in enumerate(shap_p_list_peaks):\n",
    "        ind_shap_p[0].append(index)\n",
    "        ind_shap_p[1].append(each_shap_p)\n",
    "        if ind_shap_p[1][index] > 0.05:\n",
    "            shap_ver_list_peaks.append(\"normal\")\n",
    "        else:\n",
    "            shap_ver_list_peaks.append(\"not normal\")\n",
    "    df_shap_dict = {'cond':cond_list, 'lats p':shap_p_list_lats, 'lats verdict':shap_ver_list_lats, 'cond':cond_list, 'peaks p':shap_p_list_peaks, 'peaks verdict':shap_ver_list_peaks}\n",
    "    col_shap_list = ['cond', 'lats p','lats verdict','cond', 'peaks p','peaks verdict']\n",
    "    print(\"Shapiro-Wilk normality tests for LATS (left) and PEAKS (right)\")\n",
    "    return pandas.DataFrame(data=df_shap_dict, columns = col_shap_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja tworząca zapis zgodnu ze standardami APA - działa tylko z RM ANOVĄ z R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def anova_apa_lats_then_peaks(anova_lats, anova_peaks):\n",
    "    if anova_lats[3][11] < 0.001:\n",
    "        lats_anova_p = \"< 0.001\"\n",
    "    else:\n",
    "        lats_anova_p = \"= \", str(round(anova_lats[3][11],2))\n",
    "\n",
    "    if anova_peaks[3][11] < 0.001:\n",
    "        peaks_anova_p = \"< 0.001\"\n",
    "    else:\n",
    "        peaks_anova_p = \"= \" + str(round(anova_peaks[3][11],2))\n",
    "    lats_title = 'LATS: ' + \"F(\"+str(int(anova_lats[3][3]))+','+str(int(anova_lats[3][7]))+ \") = \"+ str(round(anova_lats[3][9],2))+\" ; \" + \"p \" + lats_anova_p\n",
    "    peaks_title = 'PEAKS: ' + \"F(\"+str(int(anova_peaks[3][3]))+', '+str(int(anova_peaks[3][7]))+ \") = \"+ str(round(anova_peaks[3][9],2)) + \" ; \" + \"p \" + peaks_anova_p\n",
    "    return lats_title, peaks_title "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porównanie warunków przy pomocy testu t dla prób zależnych dla PEAKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def peaks_ph(peaks_dict, conditions):\n",
    "    peaks_pairs = []\n",
    "    for first in range(0,len(peaks_dict)):\n",
    "        for second  in range(first+1,5):\n",
    "            peaks_pairs.append((conditions[first], conditions[second]))\n",
    "    first_peaks_list = []\n",
    "    second_peaks_list = []\n",
    "    t_peaks_list = []\n",
    "    p_peaks_list = []\n",
    "    ver_peaks_list = []\n",
    "    for first, second in peaks_pairs:\n",
    "        first_peaks_list.append(first)\n",
    "        second_peaks_list.append(second)\n",
    "        ttest_peaks_results = stats.ttest_rel(peaks_dict[first],peaks_dict[second])\n",
    "        t_peaks_list.append(round(ttest_peaks_results[0],2))\n",
    "        p_peaks_list.append(round(ttest_peaks_results[1],2))\n",
    "        ind_peaks_p = [[],[]]\n",
    "    for index, each_p in enumerate(p_peaks_list):\n",
    "            ind_peaks_p[0].append(index)\n",
    "            ind_peaks_p[1].append(each_p)\n",
    "            if ind_peaks_p[1][index] > 0.05:\n",
    "                ver_peaks_list.append(str(first_peaks_list[index]) + \" = \" +\n",
    "                                      str(second_peaks_list[index]))\n",
    "            elif ind_peaks_p[1][index] <= 0.05:\n",
    "                if t_peaks_list[index] > 0:\n",
    "                    ver_peaks_list.append(str(first_peaks_list[index]) + \" > \" +\n",
    "                                          str(second_peaks_list[index]))\n",
    "                else:\n",
    "                    ver_peaks_list.append(str(first_peaks_list[index]) + \" < \" +\n",
    "                                          str(second_peaks_list[index]))\n",
    "    df_peaks_dict = {'cond1':first_peaks_list, 'cond2':second_peaks_list, 't':t_peaks_list,\n",
    "                     'p':p_peaks_list, 'verdict':ver_peaks_list}\n",
    "    col_peaks_list = ['cond1', 'cond2', 't', 'p','verdict']\n",
    "    print('Data Frame: Dependent t-test comparison for PEAKS.')\n",
    "    return pandas.DataFrame(data=df_peaks_dict, columns = col_peaks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porównanie warunków przy pomocy testu t dla prób zależnych dla LATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lats_ph(lats_dict, conditions):\n",
    "    lats_pairs = []\n",
    "    for first in range(0,len(lats_dict)):\n",
    "        for second  in range(first+1,5):\n",
    "            lats_pairs.append((conditions[first], conditions[second]))\n",
    "    first_lats_list = []\n",
    "    second_lats_list = []\n",
    "    t_lats_list = []\n",
    "    p_lats_list = []\n",
    "    ver_lats_list = []\n",
    "    for first, second in lats_pairs:\n",
    "        first_lats_list.append(first)\n",
    "        second_lats_list.append(second)\n",
    "        ttest_lats_results = stats.ttest_rel(lats_dict[first],lats_dict[second])\n",
    "        t_lats_list.append(round(ttest_lats_results[0],2))\n",
    "        p_lats_list.append(round(ttest_lats_results[1],2))\n",
    "        ind_lats_p = [[],[]]\n",
    "    for index, each_p in enumerate(p_lats_list):\n",
    "            ind_lats_p[0].append(index)\n",
    "            ind_lats_p[1].append(each_p)\n",
    "            if ind_lats_p[1][index] > 0.05:\n",
    "                ver_lats_list.append(str(first_lats_list[index]) + \" = \" +\n",
    "                                      str(second_lats_list[index]))\n",
    "            elif ind_lats_p[1][index] <= 0.05:\n",
    "                if t_lats_list[index] > 0:\n",
    "                    ver_lats_list.append(str(first_lats_list[index]) + \" > \" +\n",
    "                                          str(second_lats_list[index]))\n",
    "                else:\n",
    "                    ver_lats_list.append(str(first_lats_list[index]) + \" < \" +\n",
    "                                          str(second_lats_list[index]))\n",
    "    df_lats_dict = {'cond1':first_lats_list, 'cond2':second_lats_list, 't':t_lats_list,\n",
    "                     'p':p_lats_list, 'verdict':ver_lats_list}\n",
    "    col_lats_list = ['cond1', 'cond2', 't', 'p','verdict']\n",
    "    print('Data Frame: Dependent t-test comparison for LATS.')\n",
    "    return pandas.DataFrame(data=df_lats_dict, columns = col_lats_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
